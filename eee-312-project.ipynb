{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4920657,"sourceType":"datasetVersion","datasetId":2853663},{"sourceId":4935362,"sourceType":"datasetVersion","datasetId":2861931}],"dockerImageVersionId":30369,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import librosa\n# import librosa.display\n# import IPython.display as ipd\n\n# import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport os\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import layers, Model\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-02-06T16:44:11.279009Z","iopub.execute_input":"2023-02-06T16:44:11.279961Z","iopub.status.idle":"2023-02-06T16:44:19.284580Z","shell.execute_reply.started":"2023-02-06T16:44:11.279877Z","shell.execute_reply":"2023-02-06T16:44:19.283488Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h3> Video Data Reading </h3>","metadata":{}},{"cell_type":"code","source":"video_data = []\nframe_no = 4\nimg_width = 64\nimg_height = 64\ntarget_class = 7","metadata":{"execution":{"iopub.status.busy":"2023-02-06T16:45:17.881624Z","iopub.execute_input":"2023-02-06T16:45:17.882010Z","iopub.status.idle":"2023-02-06T16:45:17.886933Z","shell.execute_reply.started":"2023-02-06T16:45:17.881978Z","shell.execute_reply":"2023-02-06T16:45:17.885821Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h4> Ravdess Video </h4>","metadata":{}},{"cell_type":"code","source":"ravdess_actors = os.listdir('/kaggle/input/audio-visual/data/Video Speech Actor')\nravdess_actors.sort()\nvideo_path = '/kaggle/input/audio-visual/data/Video Speech Actor'\n\nfor actor in ravdess_actors:\n    folder_path = os.path.join(video_path, actor)\n    videos = os.listdir(folder_path)\n    for video in videos:\n        p2 = os.path.join(folder_path, video)\n        cam = cv2.VideoCapture(p2)\n        fps = cam.get(cv2.CAP_PROP_FPS)\n        frame_index = np.round(np.linspace(np.round(1*fps), np.round(2.3*fps), frame_no, dtype=np.int8))\n        counter = 0\n        while True:\n            success, frame = cam.read(cv2.IMREAD_COLOR)\n            if not success:\n                break\n            if counter in frame_index:\n                frame = cv2.resize(frame, (img_width, img_height), cv2.INTER_AREA)\n                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n                video_data.append((frame/255.0).astype('float32'))\n            counter = counter+1\n        cam.release()","metadata":{"execution":{"iopub.status.busy":"2023-02-06T16:45:38.767659Z","iopub.execute_input":"2023-02-06T16:45:38.768273Z","iopub.status.idle":"2023-02-06T16:56:55.243629Z","shell.execute_reply.started":"2023-02-06T16:45:38.768236Z","shell.execute_reply":"2023-02-06T16:56:55.242382Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h4> Savee Video </h4>","metadata":{}},{"cell_type":"code","source":"savee_video_path = '/kaggle/input/savee-dataset/video/video'\nfiles = os.listdir(savee_video_path)\n\nfor file in files:\n    p1 = os.path.join(savee_video_path, file)\n    cam = cv2.VideoCapture(p1)\n    fps = cam.get(cv2.CAP_PROP_FPS)\n    frame_index = np.round(np.linspace(np.round(0.5*fps), np.round(1.5*fps), frame_no, dtype=np.int8))\n    counter = 0\n    while True:\n        success, frame = cam.read(cv2.IMREAD_COLOR)\n        if not success:\n            break\n        if counter in frame_index:\n            frame = cv2.resize(frame, (img_width, img_height), cv2.INTER_AREA)\n            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n            video_data.append((frame/255.0).astype('float32'))\n        counter = counter+1\n    cam.release()","metadata":{"execution":{"iopub.status.busy":"2023-02-06T07:47:56.654295Z","iopub.execute_input":"2023-02-06T07:47:56.654999Z","iopub.status.idle":"2023-02-06T07:48:36.460923Z","shell.execute_reply.started":"2023-02-06T07:47:56.654963Z","shell.execute_reply":"2023-02-06T07:48:36.459842Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"video_data = np.array(video_data).reshape(-1, frame_no, img_width, img_height, 3)\nvideo_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-02-06T17:02:28.505099Z","iopub.execute_input":"2023-02-06T17:02:28.505822Z","iopub.status.idle":"2023-02-06T17:02:28.605236Z","shell.execute_reply.started":"2023-02-06T17:02:28.505786Z","shell.execute_reply":"2023-02-06T17:02:28.604203Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h3> Audio Data Reading </h3>","metadata":{}},{"cell_type":"code","source":"MFCC = []\nMEL_SPEC = []\nCONTRAST = []\nTONE = []\nLabels = []","metadata":{"execution":{"iopub.status.busy":"2023-02-06T17:02:32.109387Z","iopub.execute_input":"2023-02-06T17:02:32.110629Z","iopub.status.idle":"2023-02-06T17:02:32.117079Z","shell.execute_reply.started":"2023-02-06T17:02:32.110592Z","shell.execute_reply":"2023-02-06T17:02:32.116124Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h4> Ravdess Audio </h4>","metadata":{}},{"cell_type":"code","source":"emotion = {\n    '01':'neutral',\n    '02':'neutral',\n    '03':'happy',\n    '04':'sad',\n    '05':'angry',\n    '06':'fearful',\n    '07':'disgust',\n    '08':'surprised'\n}","metadata":{"execution":{"iopub.status.busy":"2023-02-06T17:02:34.997489Z","iopub.execute_input":"2023-02-06T17:02:34.997856Z","iopub.status.idle":"2023-02-06T17:02:35.003157Z","shell.execute_reply.started":"2023-02-06T17:02:34.997824Z","shell.execute_reply":"2023-02-06T17:02:35.001963Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_gender(x):\n    num = int(x.split('.')[0])\n    if num%2 == 0:\n        return 'female_'\n    else:\n        return 'male_'","metadata":{"execution":{"iopub.status.busy":"2023-02-06T09:55:01.168958Z","iopub.execute_input":"2023-02-06T09:55:01.169680Z","iopub.status.idle":"2023-02-06T09:55:01.175156Z","shell.execute_reply.started":"2023-02-06T09:55:01.169645Z","shell.execute_reply":"2023-02-06T09:55:01.174069Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"audio_actors = os.listdir('/kaggle/input/audio-visual/data/RAVDESS')\naudio_actors.sort()\n\naudio_path = '/kaggle/input/audio-visual/data/RAVDESS'\n\nfor actor in audio_actors:\n    folder_path = os.path.join(audio_path, actor)\n    audios = os.listdir(folder_path)\n    for audio in audios:\n        path = os.path.join(folder_path, audio)\n        ad, sampling = librosa.load(path, sr = 22050*2, offset=0.5, duration=1.7, res_type='kaiser_fast')\n        mfcc = np.mean(librosa.feature.mfcc(y = ad, sr=sampling, n_mfcc=10), axis=0).tolist()\n        mel_spec = np.mean(librosa.feature.melspectrogram(y = ad, sr=sampling, n_mels=10), axis=0).tolist()\n#         contrast = np.mean(librosa.feature.spectral_contrast(y = ad, sr=sampling, n_bands=6), axis=0).tolist()\n#         tone = np.mean(librosa.feature.tonnetz(y = ad, sr=sampling), axis=0).tolist()\n        MFCC.append(mfcc)\n        MEL_SPEC.append(mel_spec)\n#         CONTRAST.append(contrast)\n#         TONE.append(tone)\n        lb = audio.split('-')\n        label = emotion[lb[2]]\n        Labels.append(label)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T17:02:41.285803Z","iopub.execute_input":"2023-02-06T17:02:41.286180Z","iopub.status.idle":"2023-02-06T17:05:00.039721Z","shell.execute_reply.started":"2023-02-06T17:02:41.286124Z","shell.execute_reply":"2023-02-06T17:05:00.037988Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h4> Savee Audio </h4>","metadata":{}},{"cell_type":"code","source":"def get_emotion(x):\n    if 'sa' in x:\n        return 'sad'\n    elif 'su' in x:\n        return 'surprised'\n    elif 'a' in x:\n        return 'angry'\n    elif 'd' in x:\n        return 'disgust'\n    elif 'f' in x:\n        return 'fearful'\n    elif 'h' in x:\n        return 'happy'\n    elif 'n' in x:\n        return 'neutral'","metadata":{"execution":{"iopub.status.busy":"2023-02-06T07:53:15.023115Z","iopub.execute_input":"2023-02-06T07:53:15.023545Z","iopub.status.idle":"2023-02-06T07:53:15.030613Z","shell.execute_reply.started":"2023-02-06T07:53:15.023509Z","shell.execute_reply":"2023-02-06T07:53:15.029471Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"savee_audio_path = '/kaggle/input/savee-dataset/audio/audio'\nfiles = os.listdir(savee_audio_path)\n\nfor file in files:\n    p1 = os.path.join(savee_audio_path, file)\n    ad, sampling = librosa.load(p1, sr=22050*2, offset=0.5, duration=1.7, res_type='kaiser_fast')\n    mfcc = np.mean(librosa.feature.mfcc(y = ad, sr=sampling, n_mfcc=10), axis=0).tolist()\n    mel_spec = np.mean(librosa.feature.melspectrogram(y = ad, sr=sampling, n_mels=10), axis=0).tolist()\n#     contrast = np.mean(librosa.feature.spectral_contrast(y=ad, sr=sampling, n_bands=6), axis=0).tolist()\n#     tone = np.mean(librosa.feature.tonnetz(y = ad, sr=sampling), axis=0).tolist()\n    MFCC.append(mfcc)\n    MEL_SPEC.append(mel_spec)\n#     CONTRAST.append(contrast)\n#     TONE.append(tone)\n    label = get_emotion(file.split('.')[0])\n    Labels.append(label)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T07:53:20.767423Z","iopub.execute_input":"2023-02-06T07:53:20.767826Z","iopub.status.idle":"2023-02-06T07:54:12.202895Z","shell.execute_reply.started":"2023-02-06T07:53:20.767793Z","shell.execute_reply":"2023-02-06T07:54:12.201564Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df1 = pd.DataFrame(MFCC)\ndf2 = pd.DataFrame(MEL_SPEC)\n# df3 = pd.DataFrame(CONTRAST)\n# df4 = pd.DataFrame(TONE)\n\nprint(df1.shape)\nprint(df2.shape)\n# print(df3.shape)\n# print(df4.shape)\n\ndf1.fillna(0.0, inplace=True)\ndf2.fillna(0.0, inplace=True)\n# df3.fillna(0.0, inplace=True)\n# df4.fillna(0.0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T17:05:29.088685Z","iopub.execute_input":"2023-02-06T17:05:29.089047Z","iopub.status.idle":"2023-02-06T17:05:29.178528Z","shell.execute_reply.started":"2023-02-06T17:05:29.089016Z","shell.execute_reply":"2023-02-06T17:05:29.177492Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"audio_data = pd.concat([df1, df2], axis=1)\naudio_data.columns = np.arange(0, audio_data.shape[-1])\naudio_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-02-06T17:05:35.386548Z","iopub.execute_input":"2023-02-06T17:05:35.386949Z","iopub.status.idle":"2023-02-06T17:05:35.398686Z","shell.execute_reply.started":"2023-02-06T17:05:35.386916Z","shell.execute_reply":"2023-02-06T17:05:35.397446Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"audio_data\n# df1","metadata":{"execution":{"iopub.status.busy":"2023-02-06T17:05:49.204956Z","iopub.execute_input":"2023-02-06T17:05:49.205334Z","iopub.status.idle":"2023-02-06T17:05:49.248854Z","shell.execute_reply.started":"2023-02-06T17:05:49.205302Z","shell.execute_reply":"2023-02-06T17:05:49.247690Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n# from sklearn.preprocessing import LabelEncoder\n# from sklearn.metrics import confusion_matrix\nfrom tensorflow.keras import regularizers","metadata":{"execution":{"iopub.status.busy":"2023-02-06T17:11:12.132210Z","iopub.execute_input":"2023-02-06T17:11:12.132576Z","iopub.status.idle":"2023-02-06T17:11:12.137791Z","shell.execute_reply.started":"2023-02-06T17:11:12.132547Z","shell.execute_reply":"2023-02-06T17:11:12.136830Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"le = LabelEncoder()\nLabels = le.fit_transform(Labels)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T17:06:31.255532Z","iopub.execute_input":"2023-02-06T17:06:31.255894Z","iopub.status.idle":"2023-02-06T17:06:31.261504Z","shell.execute_reply.started":"2023-02-06T17:06:31.255862Z","shell.execute_reply":"2023-02-06T17:06:31.260398Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"le.classes_","metadata":{"execution":{"iopub.status.busy":"2023-02-06T17:06:35.385221Z","iopub.execute_input":"2023-02-06T17:06:35.385586Z","iopub.status.idle":"2023-02-06T17:06:35.400698Z","shell.execute_reply.started":"2023-02-06T17:06:35.385553Z","shell.execute_reply":"2023-02-06T17:06:35.399727Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"video_train, video_test, audio_train, audio_test, y_train, y_test = train_test_split(video_data, audio_data, Labels, test_size=0.25, shuffle=True)\n# video_train, video_test, audio_train, audio_test, y_train, y_test = train_test_split(video_data, df1, Labels, test_size=0.3, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T17:06:38.853219Z","iopub.execute_input":"2023-02-06T17:06:38.853591Z","iopub.status.idle":"2023-02-06T17:06:38.964885Z","shell.execute_reply.started":"2023-02-06T17:06:38.853557Z","shell.execute_reply":"2023-02-06T17:06:38.963809Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h3> Video Feature Extractor Model</h3>","metadata":{}},{"cell_type":"code","source":"video_model = keras.Sequential()\n\nvideo_model.add(keras.Input(shape=(frame_no, img_width, img_height, 3)))\nvideo_model.add(layers.ConvLSTM2D(64, (3, 3), activation='relu'))\nvideo_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\nvideo_model.add(layers.BatchNormalization())\nvideo_model.add(layers.MaxPooling2D((2, 2)))\nvideo_model.add(layers.Dropout(0.2))\n\nvideo_model.add(layers.Conv2D(128, (3, 3), activation='relu'))\nvideo_model.add(layers.Conv2D(128, (3, 3), activation='relu'))\nvideo_model.add(layers.BatchNormalization())\nvideo_model.add(layers.MaxPooling2D((2, 2)))\nvideo_model.add(layers.Dropout(0.2))\n\n\nvideo_model.add(layers.Conv2D(256, (3, 3), activation='relu'))\nvideo_model.add(layers.Conv2D(256, (3, 3), activation='relu'))\nvideo_model.add(layers.BatchNormalization())\nvideo_model.add(layers.MaxPooling2D((2, 2)))\nvideo_model.add(layers.Dropout(0.2))\n\nvideo_model.add(layers.Conv2D(512, (3, 3), activation='relu'))\nvideo_model.add(layers.Conv2D(512, (3, 3), activation='relu'))\nvideo_model.add(layers.BatchNormalization())\nvideo_model.add(layers.MaxPooling2D((2, 2)))\nvideo_model.add(layers.Dropout(0.2))\n\n# video_model.add(layers.GlobalAveragePooling2D())\n\nvideo_model.add(layers.Flatten())\nvideo_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-02-06T17:08:01.380794Z","iopub.execute_input":"2023-02-06T17:08:01.381189Z","iopub.status.idle":"2023-02-06T17:08:01.657789Z","shell.execute_reply.started":"2023-02-06T17:08:01.381149Z","shell.execute_reply":"2023-02-06T17:08:01.656773Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h3> Audio Feature Extractor Model</h3>","metadata":{}},{"cell_type":"code","source":"audio_model = keras.Sequential()\n\naudio_model.add(layers.Input(shape=(audio_data.shape[-1], 1)))\naudio_model.add(layers.Conv1D(64, 10, activation='relu'))\naudio_model.add(layers.Conv1D(64, 10, activation='relu'))\naudio_model.add(layers.BatchNormalization())\naudio_model.add(layers.MaxPooling1D(4))\naudio_model.add(layers.Dropout(0.2))\n\n\naudio_model.add(layers.Conv1D(128, 10, activation='relu'))\naudio_model.add(layers.Conv1D(128, 10, activation='relu'))\naudio_model.add(layers.BatchNormalization())\naudio_model.add(layers.MaxPooling1D(4))\naudio_model.add(layers.Dropout(0.2))\n\n# audio_model.add(layers.Flatten())\n# audio_model.summary()\n\n# audio_model.add(layers.Input(shape=(audio_data.shape[-1], 1)))\n# audio_model.add(layers.Conv1D(256, 8, activation='relu'))\n# audio_model.add(layers.Conv1D(256, 8, activation='relu'))\n# audio_model.add(layers.BatchNormalization())\n# audio_model.add(layers.MaxPool1D(pool_size=2))\n# audio_model.add(layers.Dropout(0.2))\n\n# audio_model.add(layers.Conv1D(128, 8, activation='relu'))\n# audio_model.add(layers.Conv1D(128, 8, activation='relu'))\n# audio_model.add(layers.BatchNormalization())\n# audio_model.add(layers.MaxPool1D(pool_size=2))\n# audio_model.add(layers.Dropout(0.2))\n# audio_model.add(layers.Conv1D(64, 8, activation='relu'))\n# audio_model.add(layers.Conv1D(64, 8, activation='relu'))    \n# audio_model.add(layers.BatchNormalization())\n# audio_model.add(layers.MaxPooling1D(pool_size=2))\n# audio_model.add(layers.Dropout(0.2))\n\naudio_model.add(layers.Flatten())\naudio_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-02-06T17:09:37.999575Z","iopub.execute_input":"2023-02-06T17:09:37.999937Z","iopub.status.idle":"2023-02-06T17:09:38.125673Z","shell.execute_reply.started":"2023-02-06T17:09:37.999906Z","shell.execute_reply":"2023-02-06T17:09:38.124581Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h3> Model Fusion </h3>","metadata":{}},{"cell_type":"code","source":"video_input = video_model.input\nvideo_output = video_model.output\naudio_input = audio_model.input\naudio_output = audio_model.output\n\n\nmerge = layers.Concatenate()([video_output, audio_output])\nout = layers.Dense(256, activation='relu', kernel_regularizer=regularizers.L2(0.01))(merge)\nout = layers.Dropout(0.2)(out)\nout = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.L2(0.01))(out)\nout = layers.Dropout(0.2)(out)\nout = layers.Dense(target_class, activation='softmax')(out)\n\nmodel = Model(inputs=[video_input, audio_input], outputs=out)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-02-06T17:11:19.140904Z","iopub.execute_input":"2023-02-06T17:11:19.141297Z","iopub.status.idle":"2023-02-06T17:11:19.189812Z","shell.execute_reply.started":"2023-02-06T17:11:19.141264Z","shell.execute_reply":"2023-02-06T17:11:19.188777Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-02-06T17:11:37.062635Z","iopub.execute_input":"2023-02-06T17:11:37.063001Z","iopub.status.idle":"2023-02-06T17:11:37.080299Z","shell.execute_reply.started":"2023-02-06T17:11:37.062971Z","shell.execute_reply":"2023-02-06T17:11:37.079242Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_check_point = tf.keras.callbacks.ModelCheckpoint(\n    filepath = '/kaggle/working/',\n    monitor = 'val_accuracy',\n    mode='max',\n    save_best_only = True\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T17:11:44.399930Z","iopub.execute_input":"2023-02-06T17:11:44.401090Z","iopub.status.idle":"2023-02-06T17:11:44.406513Z","shell.execute_reply.started":"2023-02-06T17:11:44.401046Z","shell.execute_reply":"2023-02-06T17:11:44.405463Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit([video_train, audio_train], y_train, validation_data=([video_test, audio_test], y_test), shuffle=True,\n                    batch_size = 20, callbacks=[model_check_point], epochs=60)","metadata":{"execution":{"iopub.status.busy":"2023-02-06T17:11:53.581510Z","iopub.execute_input":"2023-02-06T17:11:53.581877Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'y', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-06T11:17:44.655276Z","iopub.execute_input":"2023-02-06T11:17:44.655748Z","iopub.status.idle":"2023-02-06T11:17:45.038612Z","shell.execute_reply.started":"2023-02-06T11:17:44.655709Z","shell.execute_reply":"2023-02-06T11:17:45.037867Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nplt.plot(epochs, acc, 'y', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-06T11:17:52.569027Z","iopub.execute_input":"2023-02-06T11:17:52.569505Z","iopub.status.idle":"2023-02-06T11:17:52.825672Z","shell.execute_reply.started":"2023-02-06T11:17:52.569466Z","shell.execute_reply":"2023-02-06T11:17:52.824388Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h4> Data Visualization </h4>","metadata":{}},{"cell_type":"code","source":"path = '/kaggle/input/audio-visual/data/RAVDESS/Actor_01/03-01-02-01-02-02-01.wav'\naudio, sr = librosa.load(path, sr=22050, offset=0.5, duration=2, res_type='kaiser_fast')\n\nmfcc = np.mean(librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=10), axis=0)\nmel_spec = np.mean(librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=10), axis=0)\ncontrast = np.mean(librosa.feature.spectral_contrast(y=audio, sr=sr), axis=0)\ntone = np.mean(librosa.feature.tonnetz(y=audio, sr=sr), axis=0)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(20, 15))\nplt.subplot(411)\nlibrosa.display.specshow(mfcc)\nplt.subplot(412)\nlibrosa.display.specshow(mel_spec)\nplt.subplot(413)\nlibrosa.display.specshow(contrast)\nplt.subplot(414)\nlibrosa.display.specshow(tone)\nplt.colorbar()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nplt.subplot(221)\nplt.plot(np.mean(mfcc, axis=0))\nplt.title('mfcc')\nplt.subplot(222)\nplt.plot(np.mean(mel_spec, axis=0))\nplt.title('melspectrogram')\nplt.subplot(223)\nplt.plot(np.mean(contrast, axis=0))\nplt.title('spectral contrat')\nplt.subplot(224)\nplt.plot(np.mean(tone, axis=0))\nplt.title('tonnetz')\n","metadata":{},"outputs":[],"execution_count":null}]}